"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var audio_stream_exports = {};
__export(audio_stream_exports, {
  AudioStream: () => AudioStream
});
module.exports = __toCommonJS(audio_stream_exports);
var import_mutex = require("@livekit/mutex");
var import_audio_frame = require("./audio_frame.cjs");
var import_ffi_client = require("./ffi_client.cjs");
var import_audio_frame_pb = require("./proto/audio_frame_pb.cjs");
class AudioStream {
  constructor(track, sampleRate = 48e3, numChannels = 1) {
    /** @internal */
    this.eventQueue = [];
    /** @internal */
    this.queueResolve = null;
    /** @internal */
    this.mutex = new import_mutex.Mutex();
    this.onEvent = (ev) => {
      if (ev.message.case != "audioStreamEvent" || ev.message.value.streamHandle != this.ffiHandle.handle) {
        return;
      }
      const streamEvent = ev.message.value.message;
      switch (streamEvent.case) {
        case "frameReceived":
          const frame = import_audio_frame.AudioFrame.fromOwnedInfo(streamEvent.value.frame);
          if (this.queueResolve) {
            this.queueResolve({ done: false, value: frame });
          } else {
            this.eventQueue.push(frame);
          }
          break;
        case "eos":
          import_ffi_client.FfiClient.instance.off(import_ffi_client.FfiClientEvent.FfiEvent, this.onEvent);
          break;
      }
    };
    this.track = track;
    this.sampleRate = sampleRate;
    this.numChannels = numChannels;
    const req = new import_audio_frame_pb.NewAudioStreamRequest({
      type: import_audio_frame_pb.AudioStreamType.AUDIO_STREAM_NATIVE,
      trackHandle: track.ffi_handle.handle,
      sampleRate,
      numChannels
    });
    const res = import_ffi_client.FfiClient.instance.request({
      message: {
        case: "newAudioStream",
        value: req
      }
    });
    this.info = res.stream.info;
    this.ffiHandle = new import_ffi_client.FfiHandle(res.stream.handle.id);
    import_ffi_client.FfiClient.instance.on(import_ffi_client.FfiClientEvent.FfiEvent, this.onEvent);
  }
  async next() {
    const unlock = await this.mutex.lock();
    if (this.eventQueue.length > 0) {
      unlock();
      const value = this.eventQueue.shift();
      if (value) {
        return { done: false, value };
      } else {
        return { done: true, value: void 0 };
      }
    }
    const promise = new Promise(
      (resolve) => this.queueResolve = resolve
    );
    unlock();
    return promise;
  }
  close() {
    this.eventQueue.push(null);
    this.ffiHandle.dispose();
  }
  [Symbol.asyncIterator]() {
    return this;
  }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  AudioStream
});
//# sourceMappingURL=audio_stream.cjs.map