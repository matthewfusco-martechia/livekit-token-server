"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var audio_source_exports = {};
__export(audio_source_exports, {
  AudioSource: () => AudioSource
});
module.exports = __toCommonJS(audio_source_exports);
var import_ffi_client = require("./ffi_client.cjs");
var import_native = require("./napi/native.cjs");
var import_audio_frame_pb = require("./proto/audio_frame_pb.cjs");
class AudioSource {
  constructor(sampleRate, numChannels, queueSize = 1e3) {
    /** @internal */
    this.release = () => {
    };
    this.promise = this.newPromise();
    /** @internal */
    this.timeout = void 0;
    this.sampleRate = sampleRate;
    this.numChannels = numChannels;
    this.queueSize = queueSize;
    this.lastCapture = 0;
    this.currentQueueSize = 0;
    const req = new import_audio_frame_pb.NewAudioSourceRequest({
      type: import_audio_frame_pb.AudioSourceType.AUDIO_SOURCE_NATIVE,
      sampleRate,
      numChannels,
      queueSizeMs: queueSize
    });
    const res = import_ffi_client.FfiClient.instance.request({
      message: {
        case: "newAudioSource",
        value: req
      }
    });
    this.info = res.source.info;
    this.ffiHandle = new import_native.FfiHandle(res.source.handle.id);
  }
  get queuedDuration() {
    return Math.max(
      this.currentQueueSize - Number(process.hrtime.bigint() / BigInt(1e6)) + this.lastCapture,
      0
    );
  }
  clearQueue() {
    const req = new import_audio_frame_pb.ClearAudioBufferRequest({
      sourceHandle: this.ffiHandle.handle
    });
    import_ffi_client.FfiClient.instance.request({
      message: {
        case: "clearAudioBuffer",
        value: req
      }
    });
    this.release();
  }
  /** @internal */
  async newPromise() {
    return new Promise((resolve) => {
      this.release = resolve;
    });
  }
  async waitForPlayout() {
    return this.promise.then(() => {
      this.lastCapture = 0;
      this.currentQueueSize = 0;
      this.promise = this.newPromise();
    });
  }
  async captureFrame(frame) {
    const now = Number(process.hrtime.bigint() / BigInt(1e6));
    const elapsed = this.lastCapture === 0 ? 0 : now - this.lastCapture;
    const frameDurationMs = frame.samplesPerChannel / frame.sampleRate * 1e3;
    this.currentQueueSize += frameDurationMs - elapsed;
    this.lastCapture = now;
    if (this.timeout) {
      clearTimeout(this.timeout);
    }
    this.timeout = setTimeout(this.release, this.currentQueueSize - 50);
    const req = new import_audio_frame_pb.CaptureAudioFrameRequest({
      sourceHandle: this.ffiHandle.handle,
      buffer: frame.protoInfo()
    });
    const res = import_ffi_client.FfiClient.instance.request({
      message: { case: "captureAudioFrame", value: req }
    });
    const cb = await import_ffi_client.FfiClient.instance.waitFor((ev) => {
      return ev.message.case == "captureAudioFrame" && ev.message.value.asyncId == res.asyncId;
    });
    if (cb.error) {
      throw new Error(cb.error);
    }
  }
  async close() {
    this.ffiHandle.dispose();
  }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  AudioSource
});
//# sourceMappingURL=audio_source.cjs.map