"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var human_input_exports = {};
__export(human_input_exports, {
  HumanInput: () => HumanInput,
  HumanInputEvent: () => HumanInputEvent
});
module.exports = __toCommonJS(human_input_exports);
var import_rtc_node = require("@livekit/rtc-node");
var import_node_events = require("node:events");
var import_log = require("../log.cjs");
var import_stt = require("../stt/stt.cjs");
var import_utils = require("../utils.cjs");
var import_vad = require("../vad.cjs");
var HumanInputEvent = /* @__PURE__ */ ((HumanInputEvent2) => {
  HumanInputEvent2[HumanInputEvent2["START_OF_SPEECH"] = 0] = "START_OF_SPEECH";
  HumanInputEvent2[HumanInputEvent2["VAD_INFERENCE_DONE"] = 1] = "VAD_INFERENCE_DONE";
  HumanInputEvent2[HumanInputEvent2["END_OF_SPEECH"] = 2] = "END_OF_SPEECH";
  HumanInputEvent2[HumanInputEvent2["FINAL_TRANSCRIPT"] = 3] = "FINAL_TRANSCRIPT";
  HumanInputEvent2[HumanInputEvent2["INTERIM_TRANSCRIPT"] = 4] = "INTERIM_TRANSCRIPT";
  return HumanInputEvent2;
})(HumanInputEvent || {});
class HumanInput extends import_node_events.EventEmitter {
  #closed = false;
  #room;
  #vad;
  #stt;
  #participant;
  #subscribedTrack;
  #recognizeTask;
  #speaking = false;
  #speechProbability = 0;
  #logger = (0, import_log.log)();
  constructor(room, vad, stt, participant) {
    super();
    this.#room = room;
    this.#vad = vad;
    this.#stt = stt;
    this.#participant = participant;
    this.#room.on(import_rtc_node.RoomEvent.TrackPublished, this.#subscribeToMicrophone.bind(this));
    this.#room.on(import_rtc_node.RoomEvent.TrackSubscribed, this.#subscribeToMicrophone.bind(this));
    this.#subscribeToMicrophone();
  }
  get participant() {
    return this.#participant;
  }
  get subscribedTrack() {
    return this.#subscribedTrack;
  }
  #subscribeToMicrophone() {
    if (!this.#participant) {
      this.#logger.error("Participant is not set");
      return;
    }
    let microphonePublication = void 0;
    for (const publication of this.#participant.trackPublications.values()) {
      if (publication.source === import_rtc_node.TrackSource.SOURCE_MICROPHONE) {
        microphonePublication = publication;
        break;
      }
    }
    if (!microphonePublication) {
      return;
    }
    if (!microphonePublication.subscribed) {
      microphonePublication.setSubscribed(true);
    }
    const track = microphonePublication.track;
    if (track && track !== this.#subscribedTrack) {
      this.#subscribedTrack = track;
      if (this.#recognizeTask) {
        this.#recognizeTask.cancel();
      }
      const audioStream = new import_rtc_node.AudioStream(track, 16e3);
      this.#recognizeTask = new import_utils.CancellablePromise(async (resolve, _, onCancel) => {
        let cancelled = false;
        onCancel(() => {
          cancelled = true;
        });
        const sttStream = this.#stt.stream();
        const vadStream = this.#vad.stream();
        const audioStreamCo = async () => {
          for await (const ev of audioStream) {
            if (cancelled) return;
            sttStream.pushFrame(ev);
            vadStream.pushFrame(ev);
          }
        };
        const vadStreamCo = async () => {
          for await (const ev of vadStream) {
            if (cancelled) return;
            switch (ev.type) {
              case import_vad.VADEventType.START_OF_SPEECH:
                this.#speaking = true;
                this.emit(0 /* START_OF_SPEECH */, ev);
                break;
              case import_vad.VADEventType.INFERENCE_DONE:
                this.#speechProbability = ev.probability;
                this.emit(1 /* VAD_INFERENCE_DONE */, ev);
                break;
              case import_vad.VADEventType.END_OF_SPEECH:
                this.#speaking = false;
                this.emit(2 /* END_OF_SPEECH */, ev);
                break;
            }
          }
        };
        const sttStreamCo = async () => {
          for await (const ev of sttStream) {
            if (cancelled) return;
            if (ev.type === import_stt.SpeechEventType.FINAL_TRANSCRIPT) {
              this.emit(3 /* FINAL_TRANSCRIPT */, ev);
            } else if (ev.type == import_stt.SpeechEventType.INTERIM_TRANSCRIPT) {
              this.emit(4 /* INTERIM_TRANSCRIPT */, ev);
            }
          }
        };
        await Promise.all([audioStreamCo(), vadStreamCo(), sttStreamCo()]);
        sttStream.close();
        vadStream.close();
        resolve();
      });
    }
  }
  get speaking() {
    return this.#speaking;
  }
  get speakingProbability() {
    return this.#speechProbability;
  }
  async close() {
    if (this.#closed) {
      throw new Error("HumanInput already closed");
    }
    this.#closed = true;
    this.#room.removeAllListeners();
    this.#speaking = false;
    if (this.#recognizeTask) {
      await (0, import_utils.gracefullyCancel)(this.#recognizeTask);
    }
  }
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  HumanInput,
  HumanInputEvent
});
//# sourceMappingURL=human_input.cjs.map